name: Cartographer CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '20'
  PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: '0'

jobs:
  build-and-test:
    name: Build & Test (Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: ['20', '22']
      fail-fast: false
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Install Playwright browsers
      run: npx playwright install --with-deps chromium
    
    - name: Build TypeScript
      run: npm run build
    
    - name: Build tests
      run: npm run build:test
    
    # Fast Unit Tests (176 tests, ~0.6s)
    - name: Run unit tests
      run: |
        echo "Running unit tests..."
        npm run test:unit > tmp/test-output.txt 2>&1 || true
        cat tmp/test-output.txt
        
        # Extract test counts
        TOTAL=$(grep "ℹ tests" tmp/test-output.txt | tail -1 | awk '{print $3}')
        PASSED=$(grep "ℹ pass" tmp/test-output.txt | tail -1 | awk '{print $3}')
        FAILED=$(grep "ℹ fail" tmp/test-output.txt | tail -1 | awk '{print $3}')
        
        echo "TEST_TOTAL=$TOTAL" >> $GITHUB_ENV
        echo "TEST_PASSED=$PASSED" >> $GITHUB_ENV
        echo "TEST_FAILED=$FAILED" >> $GITHUB_ENV
        
        # Exit with error if tests failed
        if [ "$FAILED" != "0" ]; then
          echo "::error::$FAILED tests failed"
          exit 1
        fi
    
    # Prepare test fixtures for integration tests
    - name: Create test fixtures
      run: npm run pretest
      continue-on-error: true
    
    # Integration Tests (slower, separate job)
    - name: Run integration tests
      run: npm run test:integration
      continue-on-error: true
      timeout-minutes: 5
    
    # Run performance benchmark
    - name: Performance Benchmark
      run: |
        echo "Running performance benchmark..."
        node scripts/benchmark.js --pages=50 --mode=prerender
      continue-on-error: true
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-node-${{ matrix.node-version }}
        path: |
          dist-tests/
          tmp/test-output.txt
          tmp/benchmarks/
          tmp/test-reports/
        retention-days: 7
    
    - name: Test summary
      if: always()
      run: |
        echo "## Test Results 🧪" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Node.js:** ${{ matrix.node-version }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Total Tests | ${TEST_TOTAL:-N/A} |" >> $GITHUB_STEP_SUMMARY
        echo "| ✅ Passed | ${TEST_PASSED:-N/A} |" >> $GITHUB_STEP_SUMMARY
        echo "| ❌ Failed | ${TEST_FAILED:-N/A} |" >> $GITHUB_STEP_SUMMARY
        echo "| Build Status | ✅ Success |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "📦 [Download Test Artifacts](../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY

  validate-archives:
    name: Validate Atlas Archives
    runs-on: ubuntu-latest
    needs: build-and-test
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build
      run: npm run build
    
    - name: Validate example archives
      run: |
        echo "Validating Atlas v1.0 archive format..."
        node dist/src/cli/index.js validate archive/biaofolympia_raw.atls
      continue-on-error: true
